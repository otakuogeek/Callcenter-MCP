# Sistema de Dictado por Voz con IA (OpenAI Whisper)

## üéôÔ∏è Resumen

Se ha implementado un sistema completo de **dictado por voz** usando la API de **Whisper de OpenAI** para transcribir audio a texto en tiempo real. Los doctores ahora pueden dictar sus notas m√©dicas en lugar de escribirlas, mejorando significativamente la productividad.

---

## ‚ú® Caracter√≠sticas Implementadas

### **Backend**

#### **1. Endpoint de Transcripci√≥n**
- **Ruta:** `POST /api/transcription/transcribe`
- **Autenticaci√≥n:** JWT Token (Bearer)
- **Formato:** Multipart/form-data
- **Modelo:** OpenAI Whisper-1
- **Idioma:** Espa√±ol (es)

**Formatos de audio soportados:**
- ‚úÖ MP3 (audio/mpeg)
- ‚úÖ WAV (audio/wav)
- ‚úÖ WEBM (audio/webm) - **Recomendado para navegadores**
- ‚úÖ OGG (audio/ogg)
- ‚úÖ M4A (audio/m4a, audio/x-m4a)
- ‚úÖ MP4 (audio/mp4)
- ‚úÖ FLAC (audio/flac)

**L√≠mites:**
- Tama√±o m√°ximo: 25 MB
- Almacenamiento temporal: `/tmp/`
- Limpieza autom√°tica despu√©s de procesar

#### **2. Endpoint de Estado**
- **Ruta:** `GET /api/transcription/status`
- **Autenticaci√≥n:** JWT Token (Bearer)
- **Prop√≥sito:** Verificar si el servicio est√° configurado

**Respuesta:**
```json
{
  "success": true,
  "data": {
    "available": true,
    "message": "Servicio de transcripci√≥n disponible"
  }
}
```

### **Frontend**

#### **1. Componente VoiceDictationButton**
Bot√≥n reutilizable para dictado por voz con las siguientes caracter√≠sticas:

**Estados visuales:**
- üé§ **Reposo:** Icono de micr√≥fono + "Dictar"
- üî¥ **Grabando:** Icono pulsante + "Detener" (fondo rojo)
- ‚è≥ **Transcribiendo:** Spinner animado + "Transcribiendo..."

**Funcionalidades:**
- Solicita permiso de micr√≥fono al navegador
- Graba audio usando MediaRecorder API
- Env√≠a autom√°ticamente a transcribir al detener
- Muestra toasts informativos en cada paso
- Manejo robusto de errores

**Props:**
```typescript
interface VoiceDictationButtonProps {
  onTranscription: (text: string) => void;    // Callback con texto transcrito
  transcribeAudio: (audioBlob: Blob) => Promise<string>;  // Funci√≥n de transcripci√≥n
  disabled?: boolean;                          // Deshabilitar bot√≥n
  variant?: 'default' | 'outline' | 'ghost';  // Estilo del bot√≥n
  size?: 'default' | 'sm' | 'lg' | 'icon';    // Tama√±o del bot√≥n
  className?: string;                          // Clases CSS adicionales
}
```

#### **2. Integraci√≥n en Historia Cl√≠nica**

Se agregaron botones de dictado en **6 campos clave**:

| Pesta√±a | Campo | Ubicaci√≥n |
|---------|-------|-----------|
| General | Motivo de Consulta | Junto al label |
| General | Enfermedad Actual | Junto al label |
| Diagn√≥stico | Diagn√≥stico Principal | Junto al label |
| Diagn√≥stico | Observaciones Adicionales | Junto al label |
| Tratamiento | Plan de Tratamiento | Junto al label |
| Tratamiento | Prescripci√≥n M√©dica | Junto al label |

**Comportamiento:**
- El texto transcrito se **a√±ade** al contenido existente (no reemplaza)
- Se agrega un espacio autom√°ticamente si el campo ya tiene texto
- Ideal para dictar en m√∫ltiples sesiones

---

## üîß Configuraci√≥n

### **1. Variable de Entorno (Backend)**

Agregar en `/backend/.env`:

```env
# --- OpenAI API ---
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**C√≥mo obtener la API Key:**
1. Ir a https://platform.openai.com/api-keys
2. Crear una nueva API key
3. Copiar y pegar en el archivo .env
4. Reiniciar el backend: `pm2 restart cita-central-backend`

**Importante:**
- La API key debe tener permisos para usar el modelo `whisper-1`
- Se requiere cr√©dito en la cuenta de OpenAI
- Costo aproximado: $0.006 por minuto de audio

### **2. Dependencias Instaladas**

**Backend:**
```bash
npm install openai ioredis date-fns date-fns-tz
```

**Frontend:**
- No requiere dependencias adicionales (usa APIs nativas del navegador)

---

## üéØ Flujo de Uso

### **Para el Doctor:**

1. **Abrir Historia Cl√≠nica**
   - Click en "Atender" en una cita
   - Navegar a la pesta√±a deseada (General, Diagn√≥stico, etc.)

2. **Iniciar Dictado**
   - Click en bot√≥n "üé§ Dictar" junto al campo de texto
   - El navegador solicita permiso de micr√≥fono (solo la primera vez)
   - El bot√≥n cambia a "üî¥ Detener" con fondo rojo

3. **Hablar**
   - Hablar claramente cerca del micr√≥fono
   - Puede dictar varias oraciones
   - No hay l√≠mite de tiempo (recomendado: 1-2 minutos por sesi√≥n)

4. **Detener Grabaci√≥n**
   - Click en "üî¥ Detener"
   - El bot√≥n cambia a "‚è≥ Transcribiendo..."
   - El audio se env√≠a autom√°ticamente a OpenAI

5. **Ver Resultado**
   - El texto transcrito aparece en el campo
   - Se muestra un toast con preview del texto
   - Se puede editar manualmente el resultado

6. **Dictar M√°s (Opcional)**
   - Click nuevamente en "üé§ Dictar"
   - El nuevo texto se a√±ade al final del existente

---

## üìä Ejemplo de Uso

### **Escenario: Doctor dictando el motivo de consulta**

```
Doctor: "Paciente masculino de 45 a√±os que consulta por 
         dolor tor√°cico de 3 d√≠as de evoluci√≥n, tipo opresivo, 
         que irradia a brazo izquierdo, asociado a sudoraci√≥n 
         y n√°useas. Sin antecedentes de importancia."

Sistema: [Graba audio] ‚Üí [Env√≠a a Whisper] ‚Üí [Recibe transcripci√≥n]

Resultado en campo:
"Paciente masculino de 45 a√±os que consulta por dolor tor√°cico 
de 3 d√≠as de evoluci√≥n, tipo opresivo, que irradia a brazo 
izquierdo, asociado a sudoraci√≥n y n√°useas. Sin antecedentes 
de importancia."

Doctor: [Revisa y corrige si es necesario] ‚Üí [Contin√∫a con siguiente campo]
```

---

## üîç Detalles T√©cnicos

### **Backend: Flujo de Transcripci√≥n**

```typescript
1. Cliente env√≠a FormData con archivo de audio
   ‚Üì
2. Middleware de autenticaci√≥n valida JWT
   ‚Üì
3. Multer guarda archivo en /tmp/
   ‚Üì
4. Se verifica que OPENAI_API_KEY est√© configurada
   ‚Üì
5. Se lee el archivo y se crea un objeto File
   ‚Üì
6. Se env√≠a a OpenAI Whisper API
   ‚Üì
7. Se recibe transcripci√≥n en espa√±ol
   ‚Üì
8. Se elimina archivo temporal
   ‚Üì
9. Se devuelve JSON con texto transcrito
```

### **Frontend: Componente VoiceDictationButton**

```typescript
// Iniciar grabaci√≥n
const startRecording = async () => {
  // 1. Solicitar permiso de micr√≥fono
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  
  // 2. Crear MediaRecorder con codec WEBM
  const mediaRecorder = new MediaRecorder(stream, {
    mimeType: 'audio/webm;codecs=opus'
  });
  
  // 3. Acumular chunks de audio
  mediaRecorder.ondataavailable = (event) => {
    chunks.push(event.data);
  };
  
  // 4. Al detener, crear Blob y transcribir
  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(chunks, { type: 'audio/webm' });
    await transcribeRecording(audioBlob);
  };
  
  // 5. Iniciar grabaci√≥n
  mediaRecorder.start();
};
```

### **API de OpenAI Whisper**

```typescript
const transcription = await openai.audio.transcriptions.create({
  file: audioFile,              // Archivo de audio
  model: 'whisper-1',           // Modelo de Whisper
  language: 'es',               // Espa√±ol
  response_format: 'json',      // Formato de respuesta
});

// Respuesta:
// {
//   text: "Texto transcrito en espa√±ol..."
// }
```

---

## üõ°Ô∏è Manejo de Errores

### **Errores Comunes y Soluciones:**

#### **1. "Permiso de micr√≥fono denegado"**
**Causa:** Usuario rechaz√≥ el permiso o el navegador no tiene acceso

**Soluci√≥n:**
```
1. Abrir configuraci√≥n del navegador
2. Ir a Permisos ‚Üí Micr√≥fono
3. Permitir acceso para biosanarcall.site
4. Recargar la p√°gina
```

#### **2. "API key de OpenAI no configurada"**
**Causa:** Variable de entorno OPENAI_API_KEY no est√° definida

**Soluci√≥n:**
```bash
# Editar .env
nano /home/ubuntu/app/backend/.env

# Agregar:
OPENAI_API_KEY=sk-proj-xxxx...

# Reiniciar backend
pm2 restart cita-central-backend
```

#### **3. "Error al transcribir audio"**
**Causa:** Problema con la API de OpenAI (cuota, cr√©dito, etc.)

**Soluci√≥n:**
```
1. Verificar que hay cr√©dito en la cuenta de OpenAI
2. Verificar que la API key tiene permisos para Whisper
3. Revisar logs del backend: pm2 logs cita-central-backend
```

#### **4. "No se encontr√≥ ning√∫n micr√≥fono"**
**Causa:** No hay micr√≥fono conectado al dispositivo

**Soluci√≥n:**
```
- Conectar micr√≥fono o aud√≠fonos con micr√≥fono
- Verificar que el micr√≥fono est√© habilitado en el sistema operativo
- En Linux/Mac: verificar permisos de audio del navegador
```

#### **5. "Formato de audio no soportado"**
**Causa:** El navegador usa un codec no soportado

**Soluci√≥n:**
```javascript
// El componente usa WEBM por defecto (compatible con la mayor√≠a)
// Si hay problemas, el backend acepta otros formatos:
- Chrome/Edge: WEBM (opus)
- Firefox: WEBM (opus) o OGG
- Safari: MP4 (AAC) o WAV
```

---

## üìà Performance y Costos

### **Tiempos de Procesamiento:**

| Duraci√≥n Audio | Tiempo Transcripci√≥n | Tama√±o Aproximado |
|----------------|---------------------|-------------------|
| 10 segundos    | ~1-2 segundos       | ~50 KB            |
| 30 segundos    | ~2-4 segundos       | ~150 KB           |
| 1 minuto       | ~3-6 segundos       | ~300 KB           |
| 2 minutos      | ~5-10 segundos      | ~600 KB           |

### **Costos de OpenAI Whisper:**

| Concepto | Precio |
|----------|--------|
| Por minuto de audio | $0.006 USD |
| 10 minutos | $0.06 USD |
| 100 minutos | $0.60 USD |
| 1000 minutos (16.6 horas) | $6.00 USD |

**Ejemplo de uso mensual:**
- 50 consultas/d√≠a √ó 2 minutos promedio = 100 minutos/d√≠a
- 100 min/d√≠a √ó 20 d√≠as = 2000 minutos/mes
- 2000 minutos √ó $0.006 = **$12 USD/mes**

### **Optimizaciones:**

1. **Limitar duraci√≥n de grabaci√≥n:**
   - Agregar timer visual
   - Detener autom√°ticamente despu√©s de 3 minutos

2. **Comprimir audio antes de enviar:**
   - Usar bitrate m√°s bajo (16 kbps en lugar de 32 kbps)
   - Reducir sample rate a 16 kHz

3. **Cach√© local temporal:**
   - Guardar transcripciones en localStorage
   - Evitar re-transcribir si el usuario cancel√≥ sin guardar

---

## üîí Seguridad

### **Medidas Implementadas:**

1. **Autenticaci√≥n requerida:**
   - Solo doctores autenticados pueden usar el servicio
   - JWT token validado en cada request

2. **Validaci√≥n de archivos:**
   - Solo formatos de audio permitidos
   - L√≠mite de tama√±o: 25 MB
   - Verificaci√≥n de MIME type

3. **Limpieza autom√°tica:**
   - Archivos temporales eliminados despu√©s de procesar
   - Timeout de 30 segundos para limpieza en caso de error

4. **Protecci√≥n de API key:**
   - API key en variable de entorno (no en c√≥digo)
   - No se expone al frontend
   - Logs sin informaci√≥n sensible

5. **HTTPS obligatorio:**
   - MediaRecorder API solo funciona en HTTPS
   - Biosanarcall.site ya tiene SSL

---

## üé® UI/UX

### **Estados Visuales:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üé§ Dictar                           ‚îÇ  ‚Üê Estado: Reposo
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üî¥ Detener ‚óè ‚óè ‚óè                    ‚îÇ  ‚Üê Estado: Grabando (pulsante)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚è≥ Transcribiendo...  [spinner]     ‚îÇ  ‚Üê Estado: Procesando
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Toasts Informativos:**

```
‚úÖ "Grabando..."
   Hable claramente cerca del micr√≥fono

‚úÖ "Transcripci√≥n completada"
   Paciente masculino de 45 a√±os que...

‚ùå "Permiso de micr√≥fono denegado"
   Por favor, habilite el acceso...

‚ùå "Error en transcripci√≥n"
   No se pudo transcribir el audio...
```

### **Posicionamiento:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Motivo de Consulta *          [üé§ Dictar]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ [Campo de texto...]                     ‚îÇ‚îÇ
‚îÇ ‚îÇ                                         ‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì± Compatibilidad

### **Navegadores Soportados:**

| Navegador | Versi√≥n M√≠nima | MediaRecorder | WEBM Opus |
|-----------|----------------|---------------|-----------|
| Chrome    | 49+            | ‚úÖ            | ‚úÖ         |
| Firefox   | 25+            | ‚úÖ            | ‚úÖ         |
| Edge      | 79+            | ‚úÖ            | ‚úÖ         |
| Safari    | 14.1+          | ‚úÖ            | ‚ùå (usa MP4)|
| Opera     | 36+            | ‚úÖ            | ‚úÖ         |

**Nota:** Safari requiere configuraci√≥n adicional para WEBM. El backend acepta MP4 como alternativa.

### **Dispositivos:**

- ‚úÖ **Desktop:** Micr√≥fono USB, integrado, o de aud√≠fonos
- ‚úÖ **Laptop:** Micr√≥fono integrado o externo
- ‚úÖ **Tablet:** Micr√≥fono integrado (iOS 14.1+, Android Chrome)
- ‚úÖ **M√≥vil:** Micr√≥fono integrado (requiere HTTPS)

---

## üöÄ Pr√≥ximas Mejoras Sugeridas

### **Prioridad Alta:**

1. **Indicador de nivel de audio:**
   ```typescript
   // Visualizaci√≥n de onda de audio mientras graba
   const audioContext = new AudioContext();
   const analyser = audioContext.createAnalyser();
   // Mostrar barras animadas
   ```

2. **Timer visual:**
   ```typescript
   // Mostrar tiempo transcurrido
   00:15 / 03:00  [======>........]
   ```

3. **Atajos de teclado:**
   ```typescript
   // Ctrl + Shift + D: Iniciar/detener dictado
   // Esc: Cancelar grabaci√≥n
   ```

### **Prioridad Media:**

4. **Pausar/reanudar grabaci√≥n:**
   - Bot√≥n de pausa durante la grabaci√≥n
   - Continuar sin perder contexto

5. **Transcripci√≥n con puntuaci√≥n mejorada:**
   - Usar modelo de puntuaci√≥n post-procesamiento
   - Capitalizaci√≥n autom√°tica de nombres propios

6. **M√∫ltiples idiomas:**
   - Detectar idioma autom√°ticamente
   - Selector de idioma en el bot√≥n

### **Prioridad Baja:**

7. **Historial de transcripciones:**
   - Guardar transcripciones del d√≠a
   - Reutilizar frases comunes

8. **Plantillas de voz:**
   - Comandos de voz para insertar plantillas
   - "Insertar plantilla de examen f√≠sico normal"

9. **Correcci√≥n colaborativa:**
   - Entrenar modelo con correcciones del doctor
   - Mejorar precisi√≥n con el tiempo

---

## ‚úÖ Checklist de Implementaci√≥n

- ‚úÖ Instalado SDK de OpenAI en backend
- ‚úÖ Creado endpoint `/api/transcription/transcribe`
- ‚úÖ Creado endpoint `/api/transcription/status`
- ‚úÖ Registrado en rutas principales
- ‚úÖ Agregada variable de entorno `OPENAI_API_KEY`
- ‚úÖ Backend compilado y reiniciado
- ‚úÖ Creado componente `VoiceDictationButton`
- ‚úÖ Agregada funci√≥n `transcribeAudio` en hook
- ‚úÖ Integrado en 6 campos de historia cl√≠nica
- ‚úÖ Frontend compilado exitosamente
- ‚úÖ Documentaci√≥n completa

---

## üéì Conclusi√≥n

El sistema de **dictado por voz con IA** est√° completamente implementado y listo para usar. Los doctores pueden:

‚úÖ Dictar en lugar de escribir  
‚úÖ Ahorrar tiempo significativo  
‚úÖ Reducir errores de tipeo  
‚úÖ Mejorar la productividad  
‚úÖ Enfocarse m√°s en el paciente  

**Para activar:**
1. Configurar `OPENAI_API_KEY` en el backend
2. Reiniciar PM2: `pm2 restart cita-central-backend`
3. Abrir historia cl√≠nica y hacer clic en "üé§ Dictar"

**El sistema es profesional, seguro y escalable.** üéôÔ∏è‚ú®

---

**Documentado por:** GitHub Copilot Assistant  
**Fecha:** Octubre 27, 2025  
**Versi√≥n:** 1.0.0 - Dictado por Voz con OpenAI Whisper
